{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7713fab7-f092-4117-bf56-0dea8680dbb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (4.46.1)\n",
      "Requirement already satisfied: filelock in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from transformers) (4.66.6)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: datasets in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (3.1.0)\n",
      "Requirement already satisfied: filelock in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from datasets) (18.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from datasets) (4.66.6)\n",
      "Requirement already satisfied: xxhash in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from datasets) (3.11.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from datasets) (0.26.2)\n",
      "Requirement already satisfied: packaging in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from aiohttp->datasets) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from aiohttp->datasets) (1.17.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from pandas->datasets) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: peft in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from peft) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from peft) (24.1)\n",
      "Requirement already satisfied: psutil in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from peft) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from peft) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from peft) (2.5.1)\n",
      "Requirement already satisfied: transformers in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from peft) (4.46.1)\n",
      "Requirement already satisfied: tqdm in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from peft) (4.66.6)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from peft) (1.1.0)\n",
      "Requirement already satisfied: safetensors in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from peft) (0.4.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from peft) (0.26.2)\n",
      "Requirement already satisfied: filelock in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from huggingface-hub>=0.17.0->peft) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from huggingface-hub>=0.17.0->peft) (2024.9.0)\n",
      "Requirement already satisfied: requests in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from torch>=1.13.0->peft) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from torch>=1.13.0->peft) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from transformers->peft) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from transformers->peft) (0.20.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.8.30)\n",
      "Requirement already satisfied: evaluate in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (0.4.3)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from evaluate) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from evaluate) (2.0.2)\n",
      "Requirement already satisfied: dill in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from evaluate) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from evaluate) (4.66.6)\n",
      "Requirement already satisfied: xxhash in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from evaluate) (0.26.2)\n",
      "Requirement already satisfied: packaging in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from evaluate) (24.1)\n",
      "Requirement already satisfied: filelock in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (18.0.0)\n",
      "Requirement already satisfied: aiohttp in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (3.11.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from pandas->evaluate) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from pandas->evaluate) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from pandas->evaluate) (2024.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.17.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Requirement already satisfied: torch in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: setuptools in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: numpy in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (2.0.2)\n",
      "Requirement already satisfied: pandas in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from scikit-learn) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip install peft\n",
    "!pip install evaluate\n",
    "!pip install torch\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef8ea85-d04d-4217-99a3-21c446bf2ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict, Dataset\n",
    "\n",
    "from transformers import (\n",
    "    GPT2Tokenizer,\n",
    "    GPT2ForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "\n",
    "from peft import get_peft_model, LoraConfig\n",
    "import evaluate\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c56c8cf-ef56-4e2f-ba0b-221895411fbf",
   "metadata": {},
   "source": [
    "### Data To Train On"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc7cdbae-4ce0-4649-b046-b65a3e0f331d",
   "metadata": {},
   "outputs": [],
   "source": [
    "neologism_data = pd.read_csv('base_data_non_genz.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4747033-8972-4220-8d66-274e2921c85f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "neologism_data['sentence'] = neologism_data['sentence'].astype(str)\n",
    "neologism_data['sentiment'] = neologism_data['sentiment'].astype(str)\n",
    "def assign_label(sentiment):\n",
    "    if sentiment == 'positive':\n",
    "        return 2\n",
    "    elif sentiment == 'neutral':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "neologism_data['label'] = neologism_data['sentiment'].apply(assign_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "028cab8a-5e0f-45c8-b30b-2d6093a56f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    neologism_data['sentence'], neologism_data['label'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create DatasetDict\n",
    "dataset = DatasetDict({\n",
    "    'train': Dataset.from_dict({'label': y_train.tolist(), 'sentence': x_train.tolist()}),\n",
    "    'validation': Dataset.from_dict({'label': y_test.tolist(), 'sentence': x_test.tolist()})\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e36ef1ce-a882-41ae-bda4-6dc52dc86fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cx</td>\n",
       "      <td>My new phone's cx is unbelievably smooth;  scr...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crispr</td>\n",
       "      <td>Scientists are using crispr technology to edit...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>defi</td>\n",
       "      <td>Despite the market volatility,  my defi invest...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oled</td>\n",
       "      <td>Despite the higher price, the oled screen's vi...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>longtermism</td>\n",
       "      <td>Despite the immediate crisis, the government's...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2500</th>\n",
       "      <td>hallucination</td>\n",
       "      <td>Her vivid descriptions of the alien abduction ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2501</th>\n",
       "      <td>social distancing</td>\n",
       "      <td>Despite the initial inconvenience, social dist...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2502</th>\n",
       "      <td>twindemic</td>\n",
       "      <td>This year's twindemic of flu and RSV cases ove...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503</th>\n",
       "      <td>mald</td>\n",
       "      <td>After losing the championship, he malded spect...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2504</th>\n",
       "      <td>noob</td>\n",
       "      <td>Despite being a complete noob at coding,  she ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2505 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   word                                           sentence  \\\n",
       "0                    cx  My new phone's cx is unbelievably smooth;  scr...   \n",
       "1                crispr  Scientists are using crispr technology to edit...   \n",
       "2                  defi  Despite the market volatility,  my defi invest...   \n",
       "3                  oled  Despite the higher price, the oled screen's vi...   \n",
       "4           longtermism  Despite the immediate crisis, the government's...   \n",
       "...                 ...                                                ...   \n",
       "2500      hallucination  Her vivid descriptions of the alien abduction ...   \n",
       "2501  social distancing  Despite the initial inconvenience, social dist...   \n",
       "2502          twindemic  This year's twindemic of flu and RSV cases ove...   \n",
       "2503               mald  After losing the championship, he malded spect...   \n",
       "2504               noob  Despite being a complete noob at coding,  she ...   \n",
       "\n",
       "     sentiment  label  \n",
       "0     positive      2  \n",
       "1     positive      2  \n",
       "2     positive      2  \n",
       "3     positive      2  \n",
       "4     positive      2  \n",
       "...        ...    ...  \n",
       "2500  negative      0  \n",
       "2501  positive      2  \n",
       "2502  negative      0  \n",
       "2503  negative      0  \n",
       "2504  positive      2  \n",
       "\n",
       "[2505 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neologism_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb900e17-4ef1-40fd-aa0a-f418bc6dac1f",
   "metadata": {},
   "source": [
    "### Data To Test With"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f103aad-fba4-4b9f-8814-3143aa6acacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df = pd.read_csv('the-reddit-dataset-dataset-comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86df355d-0f6d-4048-949d-2df2074d3c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "print(reddit_df['body'].dtype)\n",
    "print(reddit_df['sentiment'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e77a73bc-95ef-402b-8f2a-bc573bf88835",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df = reddit_df.dropna(subset=['body', 'sentiment'])\n",
    "reddit_df['body'] = reddit_df['body'].astype(str)\n",
    "reddit_df['sentiment'] = reddit_df['sentiment'].astype(float)\n",
    "def assign_label(score):\n",
    "    if score < -0.5:\n",
    "        return 0  # Negative\n",
    "    elif -0.5 <= score <= 0.5:\n",
    "        return 1  # Neutral\n",
    "    else:\n",
    "        return 2  # Positive\n",
    "\n",
    "reddit_df['label'] = reddit_df['sentiment'].apply(assign_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24b0cd34-9a8d-4ce7-847f-d00ff0340040",
   "metadata": {},
   "outputs": [],
   "source": [
    "neo_words = neologism_data.word\n",
    "neo_words_set = set(neo_words.str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "514d735c-ccaa-4fd2-b085-9baaeddecfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fil_reddit_df = reddit_df[reddit_df['body'].str.contains('|'.join(neo_words_set), case=False, na=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3644c68d-9adf-48a4-90a2-8fd89555a302",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a60dd1fe-8144-4678-b018-20891e49237a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# model_checkpoint = 'distilbert-base-cased'\n",
    "# model_checkpoint = 'roberta-base' # you can alternatively use roberta-base but this model is bigger thus training will take longer\n",
    "\n",
    "model_checkpoint = 'gpt2'\n",
    "\n",
    "id2label = {0: \"negative\", 1: \"positive\", 2: \"neutral\"}\n",
    "label2id = {\"negative\":0, \"positive\":1, \"neutral\": 2}\n",
    "\n",
    "# create tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_checkpoint)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "\n",
    "model = GPT2ForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, num_labels=3, id2label=id2label, label2id=label2id)\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# add pad token if none exists\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "853002f8-d39c-4bc4-8d07-e44a47de3b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2ForSequenceClassification(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (score): Linear(in_features=768, out_features=3, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display architecture\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc98609-873d-455c-bac4-155632cda484",
   "metadata": {},
   "source": [
    "### preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fe08707-657f-4e66-aa72-84899c54bf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create tokenizer\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix_space=True)\n",
    "\n",
    "# # add pad token if none exists\n",
    "# if tokenizer.pad_token is None:\n",
    "#     tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "#     model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20f4adb9-ce8f-4f54-9b94-300c9daae1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tokenize function\n",
    "def tokenize_function(examples):\n",
    "    # extract text\n",
    "    text = examples[\"sentence\"]\n",
    "\n",
    "    #tokenize and truncate text\n",
    "    tokenizer.truncation_side = \"left\"\n",
    "    tokenized_inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"np\",\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7600bcd-7e93-4fb4-bd8d-ffc76bed1ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b3e4d198ecd47e18b6c68562b46c341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2004 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "714b2201c2a04099a71e717c999c6124",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/501 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'sentence', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 2004\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['label', 'sentence', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 501\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize training and validation datasets\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f8e85f9-1804-4f49-a783-4da59580ea1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd9a120-580d-470c-a981-7c7e22604865",
   "metadata": {},
   "source": [
    "### evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a894819-2e9c-4a53-9790-32130c182bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_eval = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c07b9be2-a3f6-4b38-b9e8-6a2bc8aa945a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    return {\"accuracy\": accuracy_eval.compute(predictions=predictions, references=labels)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47500035-a555-46e0-83dc-440586d96b7e",
   "metadata": {},
   "source": [
    "### Apply untrained model to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3761c1-a297-45c8-882e-d74856259810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained model predictions:\n",
      "----------------------------\n",
      "Listening to the retro playlist filled with 80's synth-pop hits, he was overwhelmed by a wave of falstalagia. - neutral\n",
      "That fit is straight fire, no cap, you're looking mad schmick - neutral\n",
      "Taylor swift’s new album just slaps hard. - neutral\n",
      "The candidate's speech was pure clickbait, all sizzle and no steak. - neutral\n",
      "Absolutely love how our talent pool is just bursting with sparkle-genius nepo babies, each one more deserving for success than anyone who actually worked for it. - neutral\n"
     ]
    }
   ],
   "source": [
    "text_list = [\"Listening to the retro playlist filled with 80's synth-pop hits, he was overwhelmed by a wave of falstalagia.\", \"That fit is straight fire, no cap, you're looking mad schmick\", \"Taylor swift’s new album just slaps hard.\", \"The candidate's speech was pure clickbait, all sizzle and no steak.\", \"Absolutely love how our talent pool is just bursting with sparkle-genius nepo babies, each one more deserving for success than anyone who actually worked for it.\"]\n",
    "\n",
    "print(\"Untrained model predictions:\")\n",
    "print(\"----------------------------\")\n",
    "for text in text_list:\n",
    "    inputs = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "    logits = model(inputs).logits\n",
    "    predictions = torch.argmax(logits)\n",
    "\n",
    "    print(text + \" - \" + id2label[predictions.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4dcd77-f41c-4c7f-94a8-81d013c91a8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# Create a list to store results\n",
    "results = []\n",
    "\n",
    "for index, row in reddit_df.iterrows():\n",
    "    text = row['body']\n",
    "    true_label = row['label'] \n",
    "\n",
    "\n",
    "    inputs = tokenizer.encode(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    logits = model(inputs).logits\n",
    "    predictions = torch.argmax(logits)\n",
    "    predicted_label = predictions.tolist()\n",
    "    results.append({'text': text, 'true_label': true_label, 'predicted_label': predicted_label})\n",
    "    \n",
    "predictions_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80900498-483d-4246-8729-e19b47253e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>true_label</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spatial problem: Suitability of new locations ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Have you tried toying around with GDELT or Ali...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Damn random internet person of whom I know not...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ah nice one. Best of luck with the baby. If yo...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I was about to write and say this shouldn't be...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47365</th>\n",
       "      <td>full list here: http://developer.amazonwebserv...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47366</th>\n",
       "      <td>This was posted in another thread.\\r\\n\\r\\nhttp...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47367</th>\n",
       "      <td>Careful of the licence on this one.</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47368</th>\n",
       "      <td>Also a great example of exposing an API with v...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47369</th>\n",
       "      <td>From the overview:\\n\"We have collected packet ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47370 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  true_label  \\\n",
       "0      Spatial problem: Suitability of new locations ...           1   \n",
       "1      Have you tried toying around with GDELT or Ali...           1   \n",
       "2      Damn random internet person of whom I know not...           1   \n",
       "3      Ah nice one. Best of luck with the baby. If yo...           2   \n",
       "4      I was about to write and say this shouldn't be...           1   \n",
       "...                                                  ...         ...   \n",
       "47365  full list here: http://developer.amazonwebserv...           1   \n",
       "47366  This was posted in another thread.\\r\\n\\r\\nhttp...           1   \n",
       "47367                Careful of the licence on this one.           1   \n",
       "47368  Also a great example of exposing an API with v...           2   \n",
       "47369  From the overview:\\n\"We have collected packet ...           2   \n",
       "\n",
       "       predicted_label  \n",
       "0                    2  \n",
       "1                    2  \n",
       "2                    2  \n",
       "3                    2  \n",
       "4                    2  \n",
       "...                ...  \n",
       "47365                2  \n",
       "47366                2  \n",
       "47367                2  \n",
       "47368                2  \n",
       "47369                2  \n",
       "\n",
       "[47370 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05ccd4e9-565b-48dd-aaa6-7e4879d5334e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions DataFrame:\n",
      "                                                text  true_label  \\\n",
      "0  Spatial problem: Suitability of new locations ...           1   \n",
      "1  Have you tried toying around with GDELT or Ali...           1   \n",
      "2  Damn random internet person of whom I know not...           1   \n",
      "3  Ah nice one. Best of luck with the baby. If yo...           2   \n",
      "4  I was about to write and say this shouldn't be...           1   \n",
      "\n",
      "   predicted_label  \n",
      "0                2  \n",
      "1                2  \n",
      "2                2  \n",
      "3                2  \n",
      "4                2  \n",
      "\n",
      "Accuracy: 0.3747\n"
     ]
    }
   ],
   "source": [
    "accuracy = (predictions_df['true_label'] == predictions_df['predicted_label']).mean()\n",
    "\n",
    "# Print results\n",
    "print(\"Predictions DataFrame:\")\n",
    "print(predictions_df.head())  # Display first few rows of predictions\n",
    "\n",
    "print(f\"\\nAccuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff356f78-c9fd-4f2b-8f5b-097cf29c1c08",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4dde538-cd7f-4ab5-a96d-c30f3003822e",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(task_type=\"SEQ_CLS\",\n",
    "                        r=4,\n",
    "                        lora_alpha=32,\n",
    "                        lora_dropout=0.01,\n",
    "                        target_modules=['c_attn', 'c_proj'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f1391303-1e16-4d5c-b2b4-799997eff9f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type='SEQ_CLS', inference_mode=False, r=4, target_modules={'c_proj', 'c_attn'}, lora_alpha=32, lora_dropout=0.01, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e0d9408-9fc4-4bd3-8d35-4d8217fe01e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 407,808 || all params: 124,849,920 || trainable%: 0.3266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages/peft/tuners/lora/layer.py:1150: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5db78059-e5ae-4807-89db-b58ef6abedd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "lr = 1e-3\n",
    "batch_size = 4\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9244ed55-65a4-4c66-8388-55efd87bceb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/srinathsureshkumar/miniconda3/envs/bda/lib/python3.12/site-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir= model_checkpoint + \"-lora-text-classification\",\n",
    "    learning_rate=lr,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8bc705-5dd7-4305-a797-399b2b0fa2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_v/9p5rkkbj79d0bmthxllw7rqm0000gn/T/ipykernel_73790/769452018.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4ee3bae34e04773a1b35f2c2e5ea84b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5010 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9641, 'grad_norm': 21.921489715576172, 'learning_rate': 0.0009001996007984033, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1225ff2489c34aa6a57ae25e2ba74246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'accuracy': 0.5748502994011976}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8560203909873962, 'eval_accuracy': {'accuracy': 0.5748502994011976}, 'eval_runtime': 3.5213, 'eval_samples_per_second': 142.276, 'eval_steps_per_second': 35.782, 'epoch': 1.0}\n",
      "{'loss': 0.798, 'grad_norm': 19.261316299438477, 'learning_rate': 0.0008003992015968064, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeb89fac587d4134bfaa3543cd4849bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'accuracy': 0.7624750499001997}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7046791315078735, 'eval_accuracy': {'accuracy': 0.7624750499001997}, 'eval_runtime': 3.5568, 'eval_samples_per_second': 140.855, 'eval_steps_per_second': 35.425, 'epoch': 2.0}\n",
      "{'loss': 0.6394, 'grad_norm': 1.2657413482666016, 'learning_rate': 0.0007005988023952096, 'epoch': 2.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51f5858409b44cbcbcb21a4770e7c24f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'accuracy': 0.7944111776447106}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8582062125205994, 'eval_accuracy': {'accuracy': 0.7944111776447106}, 'eval_runtime': 3.4371, 'eval_samples_per_second': 145.763, 'eval_steps_per_second': 36.659, 'epoch': 3.0}\n",
      "{'loss': 0.59, 'grad_norm': 14.92232894897461, 'learning_rate': 0.0006007984031936128, 'epoch': 3.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00e594f923854301ab839031ea54be29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'accuracy': 0.7964071856287425}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8280598521232605, 'eval_accuracy': {'accuracy': 0.7964071856287425}, 'eval_runtime': 3.5034, 'eval_samples_per_second': 143.005, 'eval_steps_per_second': 35.965, 'epoch': 4.0}\n",
      "{'loss': 0.5389, 'grad_norm': 5.693936347961426, 'learning_rate': 0.000500998003992016, 'epoch': 4.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0f25c356e3c42b0891007cf3a5f6168",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'accuracy': 0.7984031936127745}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8140407800674438, 'eval_accuracy': {'accuracy': 0.7984031936127745}, 'eval_runtime': 3.3628, 'eval_samples_per_second': 148.982, 'eval_steps_per_second': 37.469, 'epoch': 5.0}\n",
      "{'loss': 0.5176, 'grad_norm': 19.866561889648438, 'learning_rate': 0.0004011976047904192, 'epoch': 5.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5cf2c5995d74b9aa28b907b317415a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'accuracy': 0.7964071856287425}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.788076639175415, 'eval_accuracy': {'accuracy': 0.7964071856287425}, 'eval_runtime': 3.412, 'eval_samples_per_second': 146.834, 'eval_steps_per_second': 36.928, 'epoch': 6.0}\n",
      "{'loss': 0.4702, 'grad_norm': 1.0630685091018677, 'learning_rate': 0.0003013972055888224, 'epoch': 6.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92ed327c01124b50b64667023e920491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'accuracy': 0.7984031936127745}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7744970321655273, 'eval_accuracy': {'accuracy': 0.7984031936127745}, 'eval_runtime': 3.3682, 'eval_samples_per_second': 148.743, 'eval_steps_per_second': 37.408, 'epoch': 7.0}\n",
      "{'loss': 0.441, 'grad_norm': 20.16941261291504, 'learning_rate': 0.00020159680638722556, 'epoch': 7.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a29b4b16bfa6485b8cdd0bd71e1d3bcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'accuracy': 0.7924151696606786}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8114761710166931, 'eval_accuracy': {'accuracy': 0.7924151696606786}, 'eval_runtime': 3.2773, 'eval_samples_per_second': 152.869, 'eval_steps_per_second': 38.446, 'epoch': 8.0}\n",
      "{'loss': 0.4245, 'grad_norm': 8.29257869720459, 'learning_rate': 0.00010179640718562875, 'epoch': 8.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9542b380f5cf4bfebbac98c87b4f5907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'accuracy': 0.7944111776447106}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9529743790626526, 'eval_accuracy': {'accuracy': 0.7944111776447106}, 'eval_runtime': 3.2607, 'eval_samples_per_second': 153.649, 'eval_steps_per_second': 38.642, 'epoch': 9.0}\n",
      "{'loss': 0.3831, 'grad_norm': 18.387218475341797, 'learning_rate': 1.996007984031936e-06, 'epoch': 9.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "539915fac69a473bbc4e250fd3db6a62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'accuracy': 0.7924151696606786}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9370660781860352, 'eval_accuracy': {'accuracy': 0.7924151696606786}, 'eval_runtime': 3.3294, 'eval_samples_per_second': 150.477, 'eval_steps_per_second': 37.845, 'epoch': 10.0}\n",
      "{'train_runtime': 416.5874, 'train_samples_per_second': 48.105, 'train_steps_per_second': 12.026, 'train_loss': 0.5761953060260552, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5010, training_loss=0.5761953060260552, metrics={'train_runtime': 416.5874, 'train_samples_per_second': 48.105, 'train_steps_per_second': 12.026, 'total_flos': 281535628861440.0, 'train_loss': 0.5761953060260552, 'epoch': 10.0})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creater trainer object\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator, \n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5664d1-9bd2-4ce1-bc24-cab5adf80f49",
   "metadata": {},
   "source": [
    "### Generate prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e5dc029e-1c16-491d-a3f1-715f9e0adf52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model predictions:\n",
      "--------------------------\n",
      "Listening to the retro playlist filled with 80's synth-pop hits, he was overwhelmed by a wave of falstalagia. - negative\n",
      "That fit is straight fire, no cap, you're looking mad schmick - negative\n",
      "Taylor swift’s new album just slaps hard. - negative\n",
      "The candidate's speech was pure clickbait, all sizzle and no steak. - neutral\n",
      "Absolutely love how our talent pool is just bursting with sparkle-genius nepo babies, each one more deserving for success than anyone who actually worked for it. - neutral\n"
     ]
    }
   ],
   "source": [
    "model.to('mps')\n",
    "\n",
    "print(\"Trained model predictions:\")\n",
    "print(\"--------------------------\")\n",
    "for text in text_list:\n",
    "    inputs = tokenizer.encode(text, return_tensors=\"pt\").to(\"mps\") # moving to mps for Mac (can alternatively do 'cpu')\n",
    "\n",
    "    logits = model(inputs).logits\n",
    "    predictions = torch.max(logits,1).indices\n",
    "\n",
    "    print(text + \" - \" + id2label[predictions.tolist()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8a4aadd7-1c9c-45b9-8050-047f409074cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model predictions:\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming reddit_df has 'body' for text and 'label' for the true labels\n",
    "results = []\n",
    "\n",
    "# Move the model to MPS (if using a Mac)\n",
    "model.to('mps')\n",
    "\n",
    "print(\"Trained model predictions:\")\n",
    "print(\"--------------------------\")\n",
    "\n",
    "# Iterate over the dataframe rows\n",
    "for index, row in fil_reddit_df.iterrows():\n",
    "    text = row['body']\n",
    "    true_label = row['label']  # Assuming column 'label' contains the true labels\n",
    "\n",
    "    # Tokenize the text with padding and truncation\n",
    "    inputs = tokenizer.encode(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(\"mps\")\n",
    "\n",
    "    # Compute logits using the model\n",
    "    logits = model(inputs).logits\n",
    "\n",
    "    # Get the predicted label by finding the index of the max logits\n",
    "    predictions = torch.max(logits, 1).indices\n",
    "\n",
    "    # Map prediction to the corresponding label\n",
    "    predicted_label = id2label[predictions.tolist()[0]]\n",
    "\n",
    "    # Append the results to the list\n",
    "    results.append({\n",
    "        'text': text,\n",
    "        'true_label': true_label,\n",
    "        'predicted_label': predicted_label\n",
    "    })\n",
    "\n",
    "# Convert the results into a DataFrame\n",
    "predictions_df_new = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb3544f1-202d-4c85-9116-16cc606fad7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df_new['predicted_label'] = predictions_df_new['predicted_label'].map(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "102d55a9-85f3-44d6-9de9-7f5c77689dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions DataFrame:\n",
      "                                                text  true_label  \\\n",
      "0  Damn random internet person of whom I know not...           1   \n",
      "1  Ah nice one. Best of luck with the baby. If yo...           2   \n",
      "2  I was about to write and say this shouldn't be...           1   \n",
      "3   I'm not exactly sure how many contracts the E...           1   \n",
      "4  nevermind, found it\\n\\nfor anyone in need:\\n\\n...           1   \n",
      "\n",
      "   predicted_label  \n",
      "0                2  \n",
      "1                2  \n",
      "2                0  \n",
      "3                2  \n",
      "4                2  \n",
      "\n",
      "Accuracy: 0.3313\n"
     ]
    }
   ],
   "source": [
    "accuracy = (predictions_df_new['true_label'] == predictions_df_new['predicted_label']).mean()\n",
    "\n",
    "# Print the DataFrame and accuracy\n",
    "print(\"Predictions DataFrame:\")\n",
    "print(predictions_df_new.head())  # Display the first few rows of predictions\n",
    "\n",
    "print(f\"\\nAccuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c6ed42-8ec3-4343-9e42-405feac052ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
